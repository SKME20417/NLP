{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd46f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b565ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case_text(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a078f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"Weather is too Cloudy.Possiblity of Rain is High,Today!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667a52ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weather is too cloudy.possiblity of rain is high,today!!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_case_text(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239ac2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_num(text):\n",
    "    result =  re.sub(r'\\d+',\"*\", text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3f2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_s = \"You bought 6 candies from shop, and 4 candies are in home.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c314f28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You bought * candies from shop, and * candies are in home.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_num(input_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620be911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28a5fd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading inflect-6.0.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pydantic in c:\\users\\skme2\\appdata\\roaming\\python\\python38\\site-packages (from inflect) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from pydantic->inflect) (3.7.4.3)\n",
      "Installing collected packages: inflect\n",
      "Successfully installed inflect-6.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4498547",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = inflect.engine() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d4a432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_num(text):\n",
    "    temp_string = text.split()\n",
    "    new_str = [] \n",
    "    for word in temp_string:\n",
    "        if word.isdigit():\n",
    "            temp = q.number_to_words(word)\n",
    "            new_str.append(temp)\n",
    "        else:\n",
    "            new_str.append(word)\n",
    "            \n",
    "    temp_str = \" \".join(new_str)\n",
    "    return temp_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f6bfdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = 'You bought 6 candies from shop, and 4 candies are in home.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5e68d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You bought six candies from shop, and four candies are in home.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_num(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b758ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_punct(text):\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "132f2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"Hey, Are you excited??, After a week, we will be in Shimla!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a1bc549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey Are you excited After a week we will be in Shimla'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_punct(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "133cbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffb049ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\skme2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\skme2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c8e424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_stopwords(text): \n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    return filtered_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55cbb0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data', 'new', 'oil', '.', 'A.I', 'last', 'invention']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text = \"Data is the new oil. A.I is the last invention\"\n",
    "rem_stopwords(ex_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f125564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "stem1 = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93fa5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_words(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    stems = [stem1.stem(word) for word in word_tokens] \n",
    "    return stems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b51d5c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'is',\n",
       " 'the',\n",
       " 'new',\n",
       " 'revolut',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'in',\n",
       " 'a',\n",
       " 'day',\n",
       " 'one',\n",
       " 'individu',\n",
       " 'would',\n",
       " 'gener',\n",
       " 'terabyt',\n",
       " 'of',\n",
       " 'data',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Data is the new revolution in the World, in a day one individual would generate terabytes of data.'\n",
    "s_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd6ffcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\skme2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import wordnet \n",
    "from nltk.tokenize import word_tokenize \n",
    "lemma = wordnet.WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9c36bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_word(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    # provide context i.e. part-of-speech(pos)\n",
    "    lemmas = [lemma.lemmatize(word, pos ='v') for word in word_tokens] \n",
    "    return lemmas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ef7b259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'be',\n",
       " 'the',\n",
       " 'new',\n",
       " 'revolution',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " ',',\n",
       " 'in',\n",
       " 'a',\n",
       " 'day',\n",
       " 'one',\n",
       " 'individual',\n",
       " 'would',\n",
       " 'generate',\n",
       " 'terabytes',\n",
       " 'of',\n",
       " 'data',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Data is the new revolution in the World, in a day one individual would generate terabytes of data.'\n",
    "lemmatize_word(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f4bfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d93ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagg(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    return pos_tag(word_tokens) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25c67ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Are', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('afraid', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagg('Are you afraid of something?') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a16adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\skme2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4810814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('PRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d9af28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk import pos_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "741e8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(text, grammar): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    word_pos = pos_tag(word_tokens) \n",
    "    chunkParser = nltk.RegexpParser(grammar) \n",
    "    tree = chunkParser.parse(word_pos) \n",
    "    for subtree in tree.subtrees(): \n",
    "        print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc7b1552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT little/JJ red/JJ parrot/NN)\n",
      "  is/VBZ\n",
      "  flying/VBG\n",
      "  in/IN\n",
      "  (NP the/DT sky/NN))\n",
      "(NP the/DT little/JJ red/JJ parrot/NN)\n",
      "(NP the/DT sky/NN)\n"
     ]
    }
   ],
   "source": [
    "sentence = 'the little red parrot is flying in the sky'\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "chunking(sentence, grammar) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8c12aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\skme2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\skme2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag, ne_chunk \n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d666711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "     word_tokens = word_tokenize(text)\n",
    "     word_pos = pos_tag(word_tokens) \n",
    "     print(ne_chunk(word_pos))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "742b13fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Brain/NNP)\n",
      "  (PERSON Lara/NNP)\n",
      "  scored/VBD\n",
      "  the/DT\n",
      "  highest/JJS\n",
      "  400/CD\n",
      "  runs/NNS\n",
      "  in/IN\n",
      "  a/DT\n",
      "  test/NN\n",
      "  match/NN\n",
      "  which/WDT\n",
      "  played/VBD\n",
      "  in/IN\n",
      "  between/IN\n",
      "  (ORGANIZATION WI/NNP)\n",
      "  and/CC\n",
      "  (GPE England/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = 'Brain Lara scored the highest 400 runs in a test match which played in between WI and England.'\n",
    "ner(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be472a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iNeuron13']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sent = \"iNeuron13, Data is a new fuel\"\n",
    "r2 = re.findall(r\"^\\w+\",sent)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6114c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'splited', 'this', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print((re.split(r'\\s','We splited this sentence')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccd8cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We ', 'plited thi', ' ', 'entence']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print((re.split(r's','We splited this sentence')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a31e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('icecream', 'images')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "lists = ['icecream images', 'i immitated', 'inner peace']\n",
    "\n",
    "for i in lists:\n",
    "    q = re.match(\"(i\\w+)\\W(i\\w+)\", i)\n",
    "    \n",
    "    if q:\n",
    "        print((q.groups()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b24b75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're looking for 'playing' in 'Raju is playing outside.' Found match!\n",
      "You're looking for 'iNeuron' in 'Raju is playing outside.' no match found!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = [\"playing\", \"iNeuron\"]\n",
    "text = \"Raju is playing outside.\"\n",
    "\n",
    "for p in pattern:\n",
    "    print(\"You're looking for '%s' in '%s'\" %(p, text), end = ' ')\n",
    "    \n",
    "    if re.search(p, text):\n",
    "        print('Found match!')\n",
    "        \n",
    "    else:\n",
    "        print(\"no match found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a392185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaurav@iNeuron.ai\n",
      "Nilesh@iNeuron.ai\n",
      "Jay@iNeuron.ai\n",
      "Vikash@iNeuron.ai\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "kgf = \"Gaurav@iNeuron.ai, Nilesh@iNeuron.ai, Jay@iNeuron.ai, Vikash@iNeuron.ai\"\n",
    "\n",
    "emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', kgf)\n",
    "\n",
    "for e in emails:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4af4ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i']\n",
      "['i', 'M', 'L']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "aa = \"\"\"iNeuron13\n",
    "Machine\n",
    "Learning\"\"\"\n",
    "\n",
    "q1 = re.findall(r\"^\\w\", aa)\n",
    "q2 = re.findall(r\"^\\w\", aa, re.MULTILINE)\n",
    "print(q1)\n",
    "print(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1607b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.regexp import WhitespaceTokenizer\n",
    "m = \"'There is no need to panic. We need to work together, take small yet important measures to ensure self-protection,' the Prime Minister tweeted.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "752cc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "tokens = WhitespaceTokenizer().tokenize(m)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f72cff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'There\",\n",
       " 'is',\n",
       " 'no',\n",
       " 'need',\n",
       " 'to',\n",
       " 'panic.',\n",
       " 'We',\n",
       " 'need',\n",
       " 'to',\n",
       " 'work',\n",
       " 'together,',\n",
       " 'take',\n",
       " 'small',\n",
       " 'yet',\n",
       " 'important',\n",
       " 'measures',\n",
       " 'to',\n",
       " 'ensure',\n",
       " \"self-protection,'\",\n",
       " 'the',\n",
       " 'Prime',\n",
       " 'Minister',\n",
       " 'tweeted.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cea9c11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "my_vocab = set(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a32ed36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'There\",\n",
       " 'Minister',\n",
       " 'Prime',\n",
       " 'We',\n",
       " 'ensure',\n",
       " 'important',\n",
       " 'is',\n",
       " 'measures',\n",
       " 'need',\n",
       " 'no',\n",
       " 'panic.',\n",
       " \"self-protection,'\",\n",
       " 'small',\n",
       " 'take',\n",
       " 'the',\n",
       " 'to',\n",
       " 'together,',\n",
       " 'tweeted.',\n",
       " 'work',\n",
       " 'yet'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa50a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_st = \"'There is no need to panic. We need to work together, take small yet important measures to ensure self-protection,' the Prime Minister tweeted.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54acf3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.regexp import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83bc98db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "m_t = WordPunctTokenizer().tokenize(my_st)\n",
    "\n",
    "print(len(m_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7bb5796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\",\n",
       " 'There',\n",
       " 'is',\n",
       " 'no',\n",
       " 'need',\n",
       " 'to',\n",
       " 'panic',\n",
       " '.',\n",
       " 'We',\n",
       " 'need',\n",
       " 'to',\n",
       " 'work',\n",
       " 'together',\n",
       " ',',\n",
       " 'take',\n",
       " 'small',\n",
       " 'yet',\n",
       " 'important',\n",
       " 'measures',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'self',\n",
       " '-',\n",
       " 'protection',\n",
       " \",'\",\n",
       " 'the',\n",
       " 'Prime',\n",
       " 'Minister',\n",
       " 'tweeted',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48790b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "my_vocab = set(m_t)\n",
    "print(len(my_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0863dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'\",\n",
       " ',',\n",
       " \",'\",\n",
       " '-',\n",
       " '.',\n",
       " 'Minister',\n",
       " 'Prime',\n",
       " 'There',\n",
       " 'We',\n",
       " 'ensure',\n",
       " 'important',\n",
       " 'is',\n",
       " 'measures',\n",
       " 'need',\n",
       " 'no',\n",
       " 'panic',\n",
       " 'protection',\n",
       " 'self',\n",
       " 'small',\n",
       " 'take',\n",
       " 'the',\n",
       " 'to',\n",
       " 'together',\n",
       " 'tweeted',\n",
       " 'work',\n",
       " 'yet'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vocab         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f734dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "<FreqDist with 23 samples and 28 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\\n\")\n",
    "text1 = \"'There is no need to panic. We need to work together, take small yet important measures to ensure self-protection,' the Prime Minister tweeted.\"\n",
    "freqDist = nltk.FreqDist(word_tokenize(text1))\n",
    "print(freqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2085b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(freqDist[\"person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff2bced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keys'>\n"
     ]
    }
   ],
   "source": [
    "words = freqDist.keys()\n",
    "print(type(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6acf44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "442dfa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqDist.plot(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99b081d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "sent = \"'There is no need to panic. We need to work together, take small yet important measures to ensure self-protection,' the Prime Minister tweeted.\"\n",
    " \n",
    "text_list = sent.split(\" \")\n",
    " \n",
    "freqDist = FreqDist(text_list)\n",
    "words = list(freqDist.keys())\n",
    " \n",
    "print(freqDist['need'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4639bf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqDist.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5bd7a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb752579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\skme2\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "234883ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f444807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = TextBlob(\"I love Natural Language Processing, not you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8f7b1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('Natural', 'JJ'),\n",
       " ('Language', 'NNP'),\n",
       " ('Processing', 'NNP'),\n",
       " ('not', 'RB'),\n",
       " ('you', 'PRP')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6295aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['language processing'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "53c1c4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09db96ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4357142857142857"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5814203f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Data', 'is', 'a', 'new', 'fuel', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen = TextBlob(\"Data is a new fuel. \"\n",
    "               \"Explicit is better than implicit. \"\n",
    "               \"Simple is better than complex. \")\n",
    "               \n",
    "zen.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "971c03f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Data is a new fuel.\"),\n",
       " Sentence(\"Explicit is better than implicit.\"),\n",
       " Sentence(\"Simple is better than complex.\")]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f1195fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is a new fuel.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n"
     ]
    }
   ],
   "source": [
    "for sentence in zen.sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57f9870f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'spaces', 'per', 'indentation', 'level'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = TextBlob('Use 4 spaces per indentation level')\n",
    "\n",
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "baea85b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39b6acc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uses'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[0].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2759c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lion'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "q = Word('lions')\n",
    "q.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f99ba9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Word(\"went\")\n",
    "q.lemmatize(\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b7a4b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('goat.n.01'),\n",
       " Synset('butt.n.03'),\n",
       " Synset('capricorn.n.01'),\n",
       " Synset('capricorn.n.03')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "word = Word(\"goat\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "209ec00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").get_synsets(pos=VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8af8e6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the linear extent in space from one end to the other; the longest dimension of something that is fixed in place',\n",
       " 'continuance in time',\n",
       " 'the property of being the extent of something from beginning to end',\n",
       " 'size of the gap between two places',\n",
       " 'a section of something that is long and narrow']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"length\").definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7f70415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.wordnet import Synset\n",
    "octopus = Synset('octopus.n.02')\n",
    "shrimp = Synset('shrimp.n.03')\n",
    "octopus.path_similarity(shrimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d7c2dfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cow', 'sheep', 'octopus'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = TextBlob(\"cow sheep octopus\")\n",
    "animals.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c9fc34f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['kine', 'sheep', 'octopodes'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.words.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5075b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An you pronounce czechoslovakia?\n"
     ]
    }
   ],
   "source": [
    "g = TextBlob('Can you pronounce czechuslovakia?')\n",
    "print(g.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f22662d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('longitude', 1.0)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "k = Word('longituode')\n",
    "k.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8d9f00ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = TextBlob('She sales sea shells at the sea shore.')\n",
    "\n",
    "sent.word_counts['sea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "933a2148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.words.count('sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0db99a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.words.count('Sea', case_sensitive=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ad2c7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.noun_phrases.count('sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7dfd4624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"    \")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(u'Something is better than nothing.')\n",
    "blob.translate(from_lang=\"eng\", to='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb34e5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"There is always better than not\")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_blob = TextBlob(u\"\")\n",
    "chinese_blob.translate(from_lang=\"zh-CN\", to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e6628bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [107]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m d \u001b[38;5;241m=\u001b[39m TextBlob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textblob\\blob.py:597\u001b[0m, in \u001b[0;36mBaseBlob.detect_language\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"Detect the blob's language using the Google Translate API.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03mRequires an internet connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;124;03m:rtype: str\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    592\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTextBlob.detext_translate is deprecated and will be removed in a future release. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse the official Google Translate API instead.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m\n\u001b[0;32m    596\u001b[0m )\n\u001b[1;32m--> 597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textblob\\translate.py:76\u001b[0m, in \u001b[0;36mTranslator.detect\u001b[1;34m(self, source, host, type_)\u001b[0m\n\u001b[0;32m     70\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: source}\n\u001b[0;32m     71\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{url}\u001b[39;00m\u001b[38;5;124m&sl=auto&tk=\u001b[39m\u001b[38;5;132;01m{tk}\u001b[39;00m\u001b[38;5;124m&client=\u001b[39m\u001b[38;5;132;01m{client}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     72\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m     73\u001b[0m     tk\u001b[38;5;241m=\u001b[39m_calculate_tk(source),\n\u001b[0;32m     74\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m result, language \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m language\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textblob\\translate.py:96\u001b[0m, in \u001b[0;36mTranslator._request\u001b[1;34m(self, url, host, type_, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m host \u001b[38;5;129;01mor\u001b[39;00m type_:\n\u001b[0;32m     95\u001b[0m     req\u001b[38;5;241m.\u001b[39mset_proxy(host\u001b[38;5;241m=\u001b[39mhost, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_)\n\u001b[1;32m---> 96\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m content \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    568\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "d = TextBlob(\"    \")\n",
    "d.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6879d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"And now for something completely different.\")\n",
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "942be79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Data is a new f\")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5e15286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"DATA IS A NEW FUEL. EXPLICIT IS BETTER THAN IMPLICIT. SIMPLE IS BETTER THAN COMPLEX. \")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a7f936dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.find('than')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e462343f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_blob = TextBlob('apple')\n",
    "s_blob = TextBlob('samsumg')\n",
    "\n",
    "a_blob < s_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "02473970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_blob == 'apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ba3ecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"apple and samsumg\")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_blob + ' and ' + s_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3accc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple and samsumg'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0} and {1}\".format(a_blob,s_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95dd2c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"Now is better than never.\")\n",
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "28c350c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is a new fuel.\n",
      "---- Starts at index 0, Ends at index 19\n",
      "Explicit is better than implicit.\n",
      "---- Starts at index 20, Ends at index 53\n",
      "Simple is better than complex.\n",
      "---- Starts at index 54, Ends at index 84\n"
     ]
    }
   ],
   "source": [
    "for k in zen.sentences:\n",
    "    print(k)\n",
    "    print(\"---- Starts at index {}, Ends at index {}\".format(k.start, k.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e15ae3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "     ('I love this sandwich.', 'pos'),\n",
    "     ('this is an amazing place!', 'pos'),\n",
    "     ('I feel very good about these beers.', 'pos'),\n",
    "     ('this is my best work.', 'pos'),\n",
    "     (\"what an awesome view\", 'pos'),\n",
    "     ('I do not like this restaurant', 'neg'),\n",
    "     ('I am tired of this stuff.', 'neg'),\n",
    "     (\"I can't deal with this\", 'neg'),\n",
    "     ('he is my sworn enemy!', 'neg'),\n",
    "     ('my boss is horrible.', 'neg')\n",
    "]\n",
    "\n",
    "test = [\n",
    "     ('the beer was good.', 'pos'),\n",
    "     ('I do not enjoy my job', 'neg'),\n",
    "     (\"I ain't feeling dandy today.\", 'neg'),\n",
    "     (\"I feel amazing!\", 'pos'),\n",
    "     ('Gary is a friend of mine.', 'pos'),\n",
    "     (\"I can't believe I'm doing this.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6fef647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b1ddbc54",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m      2\u001b[0m     cl \u001b[38;5;241m=\u001b[39m NaiveBayesClassifier(fp, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.json'"
     ]
    }
   ],
   "source": [
    "with open('train.json', 'r') as fp:\n",
    "    cl = NaiveBayesClassifier(fp, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8d4d44e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"This is an amazing library!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f218ca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist = cl.prob_classify(\"I am suffering from cough and cold.\")\n",
    "prob_dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3da6ef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob(\"neg\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "60221cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob(\"pos\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cde18aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"Alcohol is good. But the hangover is horrible.\", classifier=cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f83bef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol is good.\n",
      "pos\n",
      "But the hangover is horrible.\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "for b in blob.sentences:\n",
    "    print(b)\n",
    "    print(b.classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "08e78f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "25bcd357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(my) = True              neg : pos    =      1.7 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n",
      "             contains(I) = True              neg : pos    =      1.4 : 1.0\n",
      "            contains(my) = False             pos : neg    =      1.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fe89740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [('She is my best friend.', 'pos'),\n",
    "           (\"I'm happy to have a new friend.\", 'pos'),\n",
    "           (\"Stay thirsty, my friend.\", 'pos'),             \n",
    "           (\"He ain't from around here.\", 'neg')]\n",
    "\n",
    "cl.update(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4923e822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a03b0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_word_extractor(document):\n",
    "    tokens = document.split()\n",
    "    first_word, last_word = tokens[0], tokens[-1]\n",
    "    feats = {}\n",
    "    feats[\"first({0})\".format(first_word)] = True\n",
    "    feats[\"last({0})\".format(last_word)] = False\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eb11f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = end_word_extractor(\"I love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d6226fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert features == {'last(love)': False, 'first(I)': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "57dd0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl2 = NaiveBayesClassifier(test, feature_extractor=end_word_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "567bb361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"I'm excited to try my new classifier.\", classifier=cl2)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ef3c9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7278c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.4.1-cp38-cp38-win_amd64.whl (12.1 MB)\n",
      "     --------------------------------------- 12.1/12.1 MB 40.9 MB/s eta 0:00:00\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.6/181.6 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\skme2\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (1.8.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.7-cp38-cp38-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.8/42.8 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-win_amd64.whl (113 kB)\n",
      "     ---------------------------------------- 113.0/113.0 kB ? eta 0:00:00\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.0-cp38-cp38-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 41.7 MB/s eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.4-cp38-cp38-win_amd64.whl (449 kB)\n",
      "     ------------------------------------- 449.9/449.9 kB 27.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from spacy) (1.22.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.6/58.6 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.8-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "     ---------------------------------------- 6.6/6.6 MB 28.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: wasabi, murmurhash, cymem, spacy-loggers, spacy-legacy, smart-open, preshed, langcodes, catalogue, blis, typer, srsly, thinc, pathy, spacy\n",
      "Successfully installed blis-0.7.8 catalogue-2.0.8 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.7 pathy-0.6.2 preshed-3.0.6 smart-open-5.2.1 spacy-3.4.1 spacy-legacy-3.0.9 spacy-loggers-1.0.3 srsly-2.4.4 thinc-8.1.0 typer-0.4.2 wasabi-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "05d502d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApple is looking at buying U.K. startup for $1 billion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:436\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3810ce88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_core_web_sm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [143]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01men_core_web_sm\u001b[39;00m\n\u001b[0;32m      3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m en_core_web_sm\u001b[38;5;241m.\u001b[39mload()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'en_core_web_sm'"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a53f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanfordnlp\n",
      "  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n",
      "     -------------------------------------- 158.8/158.8 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from stanfordnlp) (4.64.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from stanfordnlp) (3.19.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from stanfordnlp) (1.11.0)\n",
      "Requirement already satisfied: requests in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from stanfordnlp) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from stanfordnlp) (1.22.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from torch>=1.0.0->stanfordnlp) (3.7.4.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from requests->stanfordnlp) (1.26.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from tqdm->stanfordnlp) (0.4.5)\n",
      "Installing collected packages: stanfordnlp\n",
      "Successfully installed stanfordnlp-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bfc93ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.4.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-1.4.0%2Bcpu-cp38-cp38-win_amd64.whl (77.4 MB)\n",
      "Collecting torchvision==0.5.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.5.0%2Bcpu-cp38-cp38-win_amd64.whl (485 kB)\n",
      "Requirement already satisfied: six in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from torchvision==0.5.0+cpu) (1.14.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from torchvision==0.5.0+cpu) (1.22.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\skme2\\anaconda3\\lib\\site-packages (from torchvision==0.5.0+cpu) (9.2.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0\n",
      "    Uninstalling torchvision-0.12.0:\n",
      "      Successfully uninstalled torchvision-0.12.0\n",
      "Successfully installed torch-1.4.0+cpu torchvision-0.5.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bac512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n",
      "y\n",
      "\n",
      "Default download directory: C:\\Users\\skme2\\stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "\n",
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: C:\\Users\\skme2\\stanfordnlp_resources\\en_ewt_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 235M/235M [00:43<00:00, 5.39MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: C:\\Users\\skme2\\stanfordnlp_resources\\en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_parser.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "('Barack', '4', 'nsubj:pass')\n",
      "('Obama', '1', 'flat')\n",
      "('was', '4', 'aux:pass')\n",
      "('born', '0', 'root')\n",
      "('in', '6', 'case')\n",
      "('Hawaii', '4', 'obl')\n",
      "('.', '4', 'punct')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "stanfordnlp.download('en')   # This downloads the English models for the neural pipeline\n",
    "nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8006699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_parser.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "('Narendra', '4', 'nsubj:pass')\n",
      "('Modi', '1', 'flat')\n",
      "('was', '4', 'aux:pass')\n",
      "('born', '0', 'root')\n",
      "('in', '6', 'case')\n",
      "('India', '4', 'obl')\n",
      "('.', '4', 'punct')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp \n",
    "nlp = stanfordnlp.Pipeline(lang=\"en\") # This sets up a default neural pipeline in English\n",
    "doc = nlp(\"Narendra Modi was born in India. He became Prime minister in 2014.\")\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e246fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n",
      "y\n",
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: .\\en_ewt_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 235M/235M [00:43<00:00, 5.37MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: .\\en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '.\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '.\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': '.\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'batch_size': 3000, 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "<Token index=1;words=[<Word index=1;text=Barack;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=2;words=[<Word index=2;text=Obama;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=3;words=[<Word index=3;text=was;upos=AUX;xpos=VBD;feats=Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin>]>\n",
      "<Token index=4;words=[<Word index=4;text=born;upos=VERB;xpos=VBN;feats=Tense=Past|VerbForm=Part|Voice=Pass>]>\n",
      "<Token index=5;words=[<Word index=5;text=in;upos=ADP;xpos=IN;feats=_>]>\n",
      "<Token index=6;words=[<Word index=6;text=Hawaii;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
      "<Token index=7;words=[<Word index=7;text=.;upos=PUNCT;xpos=.;feats=_>]>\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "MODELS_DIR = '.'\n",
    "stanfordnlp.download('en', MODELS_DIR) # Download the English models\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,pos', models_dir=MODELS_DIR, treebank='en_ewt', use_gpu=True, pos_batch_size=3000) # Build the pipeline, specify part-of-speech processor's batch size\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\") # Run the pipeline on input text\n",
    "doc.sentences[0].print_tokens() # Look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4cbfe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "====== Sentence 1 tokens =======\n",
      "index:   1\ttoken: This\n",
      "index:   2\ttoken: is\n",
      "index:   3\ttoken: a\n",
      "index:   4\ttoken: test\n",
      "index:   5\ttoken: sentence\n",
      "index:   6\ttoken: for\n",
      "index:   7\ttoken: stanfordnlp\n",
      "index:   8\ttoken: .\n",
      "====== Sentence 2 tokens =======\n",
      "index:   1\ttoken: This\n",
      "index:   2\ttoken: is\n",
      "index:   3\ttoken: another\n",
      "index:   4\ttoken: sentence\n",
      "index:   5\ttoken: .\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize', lang='en')\n",
    "doc = nlp(\"This is a test sentence for stanfordnlp. This is another sentence.\")\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(f\"====== Sentence {i+1} tokens =======\")\n",
    "    print(*[f\"index: {token.index.rjust(3)}\\ttoken: {token.text}\" for token in sentence.tokens], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dbd2112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"fr_gsd\" for language \"fr\".\n",
      "Would you like to download the models for: fr_gsd now? (Y/n)\n",
      "y\n",
      "\n",
      "Default download directory: C:\\Users\\skme2\\stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "\n",
      "\n",
      "Downloading models for: fr_gsd\n",
      "Download location: C:\\Users\\skme2\\stanfordnlp_resources\\fr_gsd_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 235M/235M [00:53<00:00, 4.38MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: C:\\Users\\skme2\\stanfordnlp_resources\\fr_gsd_models.zip\n",
      "Extracting models file for: fr_gsd\n",
      "Cleaning up...Done.\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd_tokenizer.pt', 'lang': 'fr', 'shorthand': 'fr_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: mwt\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd_mwt_expander.pt', 'lang': 'fr', 'shorthand': 'fr_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "Done loading processors!\n",
      "---\n",
      "token: Alors    \t\twords: [<Word index=1;text=Alors>]\n",
      "token: encore   \t\twords: [<Word index=2;text=encore>]\n",
      "token: inconnu  \t\twords: [<Word index=3;text=inconnu>]\n",
      "token: du       \t\twords: [<Word index=4;text=de>, <Word index=5;text=le>]\n",
      "token: grand    \t\twords: [<Word index=6;text=grand>]\n",
      "token: public   \t\twords: [<Word index=7;text=public>]\n",
      "token: ,        \t\twords: [<Word index=8;text=,>]\n",
      "token: Emmanuel \t\twords: [<Word index=9;text=Emmanuel>]\n",
      "token: Macron   \t\twords: [<Word index=10;text=Macron>]\n",
      "token: devient  \t\twords: [<Word index=11;text=devient>]\n",
      "token: en       \t\twords: [<Word index=12;text=en>]\n",
      "token: 2014     \t\twords: [<Word index=13;text=2014>]\n",
      "token: ministre \t\twords: [<Word index=14;text=ministre>]\n",
      "token: de       \t\twords: [<Word index=15;text=de>]\n",
      "token: l'       \t\twords: [<Word index=16;text=l'>]\n",
      "token: conomie \t\twords: [<Word index=17;text=conomie>]\n",
      "token: ,        \t\twords: [<Word index=18;text=,>]\n",
      "token: de       \t\twords: [<Word index=19;text=de>]\n",
      "token: l'       \t\twords: [<Word index=20;text=l'>]\n",
      "token: Industrie\t\twords: [<Word index=21;text=Industrie>]\n",
      "token: et       \t\twords: [<Word index=22;text=et>]\n",
      "token: du       \t\twords: [<Word index=23;text=de>, <Word index=24;text=le>]\n",
      "token: Numrique\t\twords: [<Word index=25;text=Numrique>]\n",
      "token: .        \t\twords: [<Word index=26;text=.>]\n",
      "\n",
      "word: Alors    \t\ttoken parent:1-Alors\n",
      "word: encore   \t\ttoken parent:2-encore\n",
      "word: inconnu  \t\ttoken parent:3-inconnu\n",
      "word: de       \t\ttoken parent:4-5-du\n",
      "word: le       \t\ttoken parent:4-5-du\n",
      "word: grand    \t\ttoken parent:6-grand\n",
      "word: public   \t\ttoken parent:7-public\n",
      "word: ,        \t\ttoken parent:8-,\n",
      "word: Emmanuel \t\ttoken parent:9-Emmanuel\n",
      "word: Macron   \t\ttoken parent:10-Macron\n",
      "word: devient  \t\ttoken parent:11-devient\n",
      "word: en       \t\ttoken parent:12-en\n",
      "word: 2014     \t\ttoken parent:13-2014\n",
      "word: ministre \t\ttoken parent:14-ministre\n",
      "word: de       \t\ttoken parent:15-de\n",
      "word: l'       \t\ttoken parent:16-l'\n",
      "word: conomie \t\ttoken parent:17-conomie\n",
      "word: ,        \t\ttoken parent:18-,\n",
      "word: de       \t\ttoken parent:19-de\n",
      "word: l'       \t\ttoken parent:20-l'\n",
      "word: Industrie\t\ttoken parent:21-Industrie\n",
      "word: et       \t\ttoken parent:22-et\n",
      "word: de       \t\ttoken parent:23-24-du\n",
      "word: le       \t\ttoken parent:23-24-du\n",
      "word: Numrique\t\ttoken parent:25-Numrique\n",
      "word: .        \t\ttoken parent:26-.\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "stanfordnlp.download('fr') \n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt', lang='fr')\n",
    "doc = nlp(\"Alors encore inconnu du grand public, Emmanuel Macron devient en 2014 ministre de l'conomie, de l'Industrie et du Numrique.\")\n",
    "print(*[f'token: {token.text.ljust(9)}\\t\\twords: {token.words}' for sent in doc.sentences for token in sent.tokens], sep='\\n')\n",
    "print('')\n",
    "print(*[f'word: {word.text.ljust(9)}\\t\\ttoken parent:{word.parent_token.index+\"-\"+word.parent_token.text}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d291cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "word: Barack \tupos: PROPN\txpos: NNP\n",
      "word: Obama \tupos: PROPN\txpos: NNP\n",
      "word: was \tupos: AUX\txpos: VBD\n",
      "word: born \tupos: VERB\txpos: VBN\n",
      "word: in \tupos: ADP\txpos: IN\n",
      "word: Hawaii \tupos: PROPN\txpos: NNP\n",
      "word: . \tupos: PUNCT\txpos: .\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos')\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
    "print(*[f'word: {word.text+\" \"}\\tupos: {word.upos}\\txpos: {word.xpos}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f871be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "Done loading processors!\n",
      "---\n",
      "word: Barack \tlemma: Barack\n",
      "word: Obama \tlemma: Obama\n",
      "word: was \tlemma: be\n",
      "word: born \tlemma: bear\n",
      "word: in \tlemma: in\n",
      "word: Hawaii \tlemma: Hawaii\n",
      "word: . \tlemma: .\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma')\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c58909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd_tokenizer.pt', 'lang': 'fr', 'shorthand': 'fr_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: mwt\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd_mwt_expander.pt', 'lang': 'fr', 'shorthand': 'fr_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd.pretrain.pt', 'lang': 'fr', 'shorthand': 'fr_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd_lemmatizer.pt', 'lang': 'fr', 'shorthand': 'fr_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd_parser.pt', 'pretrain_path': 'C:\\\\Users\\\\skme2\\\\stanfordnlp_resources\\\\fr_gsd_models\\\\fr_gsd.pretrain.pt', 'lang': 'fr', 'shorthand': 'fr_gsd', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "index:  1\tword: Van        \tgovernor index: 3\tgovernor: grandit    \tdeprel: nsubj\n",
      "index:  2\tword: Gogh       \tgovernor index: 1\tgovernor: Van        \tdeprel: flat:name\n",
      "index:  3\tword: grandit    \tgovernor index: 0\tgovernor: root       \tdeprel: root\n",
      "index:  4\tword:           \tgovernor index: 6\tgovernor: sein       \tdeprel: case\n",
      "index:  5\tword: le         \tgovernor index: 6\tgovernor: sein       \tdeprel: det\n",
      "index:  6\tword: sein       \tgovernor index: 3\tgovernor: grandit    \tdeprel: obl\n",
      "index:  7\tword: d'         \tgovernor index: 9\tgovernor: famille    \tdeprel: case\n",
      "index:  8\tword: une        \tgovernor index: 9\tgovernor: famille    \tdeprel: det\n",
      "index:  9\tword: famille    \tgovernor index: 6\tgovernor: sein       \tdeprel: nmod\n",
      "index: 10\tword: de         \tgovernor index: 13\tgovernor: bourgeoisie\tdeprel: case\n",
      "index: 11\tword: l'         \tgovernor index: 13\tgovernor: bourgeoisie\tdeprel: det\n",
      "index: 12\tword: ancienne   \tgovernor index: 13\tgovernor: bourgeoisie\tdeprel: amod\n",
      "index: 13\tword: bourgeoisie\tgovernor index: 9\tgovernor: famille    \tdeprel: nmod\n",
      "index: 14\tword: .          \tgovernor index: 3\tgovernor: grandit    \tdeprel: punct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma,depparse', lang='fr')\n",
    "doc = nlp(\"Van Gogh grandit au sein d'une famille de l'ancienne bourgeoisie.\")\n",
    "print(*[f\"index: {word.index.rjust(2)}\\tword: {word.text.ljust(11)}\\tgovernor index: {word.governor}\\tgovernor: {(doc.sentences[0].words[word.governor-1].text if word.governor > 0 else 'root').ljust(11)}\\tdeprel: {word.dependency_relation}\" for word in doc.sentences[0].words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44bc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
